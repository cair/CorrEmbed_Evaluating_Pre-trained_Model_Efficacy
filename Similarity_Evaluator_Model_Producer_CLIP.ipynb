{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import Database_connector\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Database_Settings import DB_SETTINGS\n",
    "import Database_connector\n",
    "from mysql.connector import (connection)\n",
    "from PIL import Image\n",
    "\n",
    "PICKLED_DATA_FOLDER = \"Pickled_Data/\"\n",
    "PICKLED_PICTURES_FILE = \"pictures_embeddings_resnet152_df.pkl\"\n",
    "PICKLED_OUTFIRS_FILE = \"active_outfits_df.pkl\"\n",
    "\n",
    "PICTURES_DROP_COLUMNS = [\"contentType\", \"status\", \"displayOrder\", \"sourceURL\", \"embeddings\"]\n",
    "#PICTURES_DROP_COLUMNS = []\n",
    "OUTFITS_DROP_COLUMNS = ['owner', 'name', 'brand', 'isPublic', 'isDeleted', 'meta.validFrom', 'meta.validTo', \"Outfit_size\"]\n",
    "\n",
    "def get_pictures_df(path):\n",
    "    pictures_df = pd.read_pickle(path)\n",
    "    #pictures_df = pictures_df.drop(columns=PICTURES_DROP_COLUMNS)\n",
    "    pictures_df = pictures_df.drop(columns=pictures_df.columns[2:])\n",
    "    return pictures_df\n",
    "\n",
    "def get_outfits_df(path):\n",
    "    outfits_df = pd.read_pickle(path)\n",
    "    outfits_df = outfits_df.drop(columns=OUTFITS_DROP_COLUMNS)\n",
    "    return outfits_df\n",
    "\n",
    "def prepare_data(pictures_df_path = PICKLED_DATA_FOLDER + PICKLED_PICTURES_FILE, outfits_df_path = PICKLED_DATA_FOLDER + PICKLED_OUTFIRS_FILE):\n",
    "    pictures_df = get_pictures_df(pictures_df_path)\n",
    "    outfits_df = get_outfits_df(outfits_df_path)\n",
    "    return pictures_df, outfits_df\n",
    "\n",
    "def picture_exists(picture_id, pictures_dir_path):\n",
    "    return os.path.isfile(pictures_dir_path + os.sep + picture_id + \".jpg\")\n",
    "\n",
    "def find_missing_pictures(pictures_df, pictures_dir_path):\n",
    "    pictures_df[\"file_exists\"] = pictures_df[\"id\"].apply(lambda x : picture_exists(x, pictures_dir_path))\n",
    "    return pictures_df[\"file_exists\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>picture.00058abb53434872ae9bb4270ae21f8e</td>\n",
       "      <td>outfit.98f32aaf08bc4ff09c44e6e11e9199bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>picture.00063f52c36d43ada95da45f819b30b4</td>\n",
       "      <td>outfit.9fd1c42c3db543c5b6e53b0db1ee8c0f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picture.0008443461814f5c988f123718bbd20e</td>\n",
       "      <td>outfit.a7539783b6e94591bdf4e10339afc1d7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>picture.000a5db3362049aebcc1eb2bf7bde95f</td>\n",
       "      <td>outfit.745fa2bc8156478bac6c0f7d46dadbda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>picture.000ddec26b7a4aa495e2d7db9e9585e9</td>\n",
       "      <td>outfit.40d4e8f739a74e488769b16f8f87ca83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "1  picture.00058abb53434872ae9bb4270ae21f8e  \\\n",
       "2  picture.00063f52c36d43ada95da45f819b30b4   \n",
       "3  picture.0008443461814f5c988f123718bbd20e   \n",
       "4  picture.000a5db3362049aebcc1eb2bf7bde95f   \n",
       "6  picture.000ddec26b7a4aa495e2d7db9e9585e9   \n",
       "\n",
       "                                     owner  \n",
       "1  outfit.98f32aaf08bc4ff09c44e6e11e9199bc  \n",
       "2  outfit.9fd1c42c3db543c5b6e53b0db1ee8c0f  \n",
       "3  outfit.a7539783b6e94591bdf4e10339afc1d7  \n",
       "4  outfit.745fa2bc8156478bac6c0f7d46dadbda  \n",
       "6  outfit.40d4e8f739a74e488769b16f8f87ca83  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pictures_df, outfits_df = prepare_data(pictures_df_path=\"../FREja_dataset_processing/pictures_embeddings_resnet152_df.pkl\"\n",
    "#                                        , outfits_df_path=\"../FREja_dataset_processing/active_outfits_df.pkl\")\n",
    "\n",
    "pictures_df, outfits_df = prepare_data(pictures_df_path=\"Pickled_Data/active_outfit_pictures_df.pkl\", outfits_df_path=\"Pickled_Data/active_outfits_df.pkl\")\n",
    "pictures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICTURES_DIR_PATH = \"../FREja_dataset_processing/Filtered_pictures/\"\n",
    "DF_SPLITS = 200\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "EMBEDDINGS_SAVE_DIR = \"Pickled_Data/Embeddings_CLIP/\"\n",
    "EMBEDDINGS_PICTURES_DIR = f\"{EMBEDDINGS_SAVE_DIR}pictures/\"\n",
    "\n",
    "if not os.path.isdir(EMBEDDINGS_SAVE_DIR):\n",
    "    os.mkdir(EMBEDDINGS_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import copy\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "import Retrieve_Image_Bucket_Data\n",
    "\n",
    "def load_local_image(image_id):\n",
    "    file_path = EMBEDDINGS_PICTURES_DIR + image_id\n",
    "    image = read_image(file_path, mode=ImageReadMode.RGB)\n",
    "    return image\n",
    "\n",
    "def image_to_embedding(model_e, image_id, d_widget, index_num):\n",
    "    d_widget.value = f\"Converting file number: {index_num}\"\n",
    "\n",
    "    try:\n",
    "        input_tensor = load_local_image(image_id)\n",
    "    except:\n",
    "        print(f\"Could not load image: {image_id}, downloading from bucket...\")\n",
    "        input_tensor = Retrieve_Image_Bucket_Data.download_picture(bucket, image_id, \"Temp.jpg\", image_format=\"torch\")\n",
    "    embedding = model_e(input_tensor)\n",
    "    return embedding[0].squeeze().cpu()\n",
    "\n",
    "def get_df_embeddings(pictures_df, embedding_model, preprocess):\n",
    "    display_out = ipywidgets.HTML()\n",
    "    display(display_out)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        embedding_model.to('cuda')\n",
    "\n",
    "    split_dfs = np.array_split(pictures_df, DF_SPLITS)\n",
    "    with torch.no_grad():\n",
    "        for df_split in tqdm(split_dfs):\n",
    "            df_split[\"embeddings\"] = df_split.apply(lambda row: image_to_embedding(preprocess, embedding_model, row[\"id\"], display_out, row.name), axis=1)\n",
    "    embedding_df = pd.concat(split_dfs)\n",
    "    return embedding_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torchvision.models import quantization\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import Retrieve_Image_Bucket_Data\n",
    "\n",
    "class Embedding_Config():\n",
    "    class exception_hack(Exception):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    class Parasite_Module(torch.nn.Module):\n",
    "        def __init__(self, host_layer, include_host=True):\n",
    "            super().__init__()\n",
    "            self.host_layer = host_layer\n",
    "            self.include_host = include_host\n",
    "\n",
    "        def forward(self, x):\n",
    "            if self.include_host:\n",
    "                x = self.host_layer(x)\n",
    "            raise Embedding_Config.exception_hack(x)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.use_cuda = None\n",
    "        \n",
    "        self.weights = None\n",
    "        self.transforms = None\n",
    "        self.model = None\n",
    "        self.model_save_name = None\n",
    "        self.bucket = Retrieve_Image_Bucket_Data.get_bucket()\n",
    "\n",
    "    def load_model(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def prepare_model(self):\n",
    "        model = self.load_model()\n",
    "        if self.use_cuda:\n",
    "            model.to(DEVICE)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def print_config_summary(self):\n",
    "        print(f\"PKL name: {self.model_save_name} | Model: {type(self.model).__name__} | Weights: {type(self.weights).__name__} | {self.weights.name}\")\n",
    "\n",
    "    def load_images(self, image_series):\n",
    "        image_tensors = self.load_image_series_torchvision(image_series)\n",
    "        formatted_images = [self.transforms(test_img).unsqueeze(0) for test_img in image_tensors]\n",
    "        formatted_images = torch.vstack(formatted_images)\n",
    "        if self.use_cuda:\n",
    "            formatted_images = formatted_images.to(DEVICE)\n",
    "        return formatted_images\n",
    "    \n",
    "    def load_image_series_torchvision(self, image_series):\n",
    "        images = []\n",
    "        for image_id in image_series:\n",
    "            try:\n",
    "                input_tensor = load_local_image(image_id)\n",
    "            except:\n",
    "                print(f\"Could not load image: {image_id}, downloading from bucket...\")\n",
    "                input_tensor = Retrieve_Image_Bucket_Data.download_picture(self.bucket, image_id, \"Temp.jpg\", image_format=\"torch\")\n",
    "            images.append(input_tensor)\n",
    "        return images\n",
    "    \n",
    "    def get_embeddings(self, image_tensors):\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                embeddings = self.model(image_tensors)\n",
    "            except self.exception_hack as e:\n",
    "                embeddings = e.args[0]\n",
    "        # Reduce to half precision to save space and load time\n",
    "        forward_embeddings = embeddings.cpu()#embeddings.half().cpu()\n",
    "        return forward_embeddings.half()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Create a custom layer that adds print functionality\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super(PrintLayer, self).__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Layer: {self.layer.__class__.__name__}, Input shape: {x.shape}\")\n",
    "        return self.layer(x)\n",
    "\n",
    "# Subclass the ResNet50 model to create a custom model\n",
    "class CustomResNet50(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(CustomResNet50, self).__init__()\n",
    "        for name, layer in original_model.named_children():\n",
    "            setattr(self, name, PrintLayer(layer))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, layer in self.named_children():\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_H_14_E2E_Config(Embedding_Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = True\n",
    "\n",
    "        self.weights = models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "        self.transforms = self.weights.transforms(antialias=True)\n",
    "        self.model = self.prepare_model()\n",
    "        self.model_save_name = f\"{self.__class__.__name__}.pkl\"\n",
    "        self.print_config_summary()\n",
    "        \n",
    "    def load_model(self):\n",
    "        model = models.vit_h_14(weights=self.weights)\n",
    "        model.heads.head = self.Parasite_Module(model.heads.head, include_host=True)\n",
    "        return model\n",
    "\n",
    "class ViT_H_14_E2E_final(Embedding_Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = True\n",
    "\n",
    "        self.weights = models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "        self.transforms = self.weights.transforms(antialias=True)\n",
    "        self.model = self.prepare_model()\n",
    "        self.model_save_name = f\"{self.__class__.__name__}.pkl\"\n",
    "        self.print_config_summary()\n",
    "        \n",
    "    def load_model(self):\n",
    "        model = models.vit_h_14(weights=self.weights)\n",
    "        model.heads.head = self.Parasite_Module(model.heads.head, include_host=False)\n",
    "        return model\n",
    "\n",
    "class resnet50_V1_Config(Embedding_Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = True\n",
    "\n",
    "        self.weights = models.ResNet50_Weights.IMAGENET1K_V1\n",
    "        self.transforms = self.weights.transforms(antialias=True)\n",
    "        self.model = self.prepare_model()\n",
    "        self.model_save_name = \"resnet50_v1.pkl\"\n",
    "        self.print_config_summary()\n",
    "    \n",
    "    def model_forward_append(self, original_forward):\n",
    "        def new_forward(x):\n",
    "            x = original_forward(x)\n",
    "            print(x.shape)\n",
    "            return x\n",
    "        return new_forward\n",
    "\n",
    "    def load_model(self):\n",
    "        model = models.resnet50(weights=self.weights)\n",
    "        model.fc = self.Parasite_Module(model.fc, include_host=False)\n",
    "        model = CustomResNet50(model)\n",
    "        return model\n",
    "\n",
    "class EfficientNet_V2_L_final(Embedding_Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = True\n",
    "\n",
    "        self.weights = models.EfficientNet_V2_L_Weights.IMAGENET1K_V1\n",
    "        self.transforms = self.weights.transforms()\n",
    "        self.model = self.prepare_model()\n",
    "        self.model_save_name = f\"{self.__class__.__name__}.pkl\"\n",
    "        self.print_config_summary()\n",
    "        \n",
    "    def load_model(self):\n",
    "        model = models.efficientnet_v2_l(weights=self.weights)\n",
    "        model.classifier[1] = self.Parasite_Module(model.classifier[1], include_host=False)\n",
    "        return model\n",
    "\n",
    "class ConvNext_Large_v1_final(Embedding_Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.use_cuda = True\n",
    "\n",
    "        self.weights = models.ConvNeXt_Large_Weights.IMAGENET1K_V1\n",
    "        self.transforms = self.weights.transforms()\n",
    "        self.model = self.prepare_model()\n",
    "        self.model_save_name = f\"{self.__class__.__name__}.pkl\"\n",
    "        self.print_config_summary()\n",
    "        \n",
    "    def load_model(self):\n",
    "        model = models.convnext_large(weights=self.weights)\n",
    "        model.classifier[2] = self.Parasite_Module(model.classifier[2], include_host=False)\n",
    "        return model\n",
    "\n",
    "test_config = resnet50_V1_Config()\n",
    "test_loaded_images = test_config.load_images(pictures_df[\"id\"][:10])\n",
    "test_embeddings = test_config.get_embeddings(test_loaded_images)\n",
    "test_loaded_images.shape, test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>owner</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>isPublic</th>\n",
       "      <th>isDeleted</th>\n",
       "      <th>type</th>\n",
       "      <th>keywords</th>\n",
       "      <th>retailPrice</th>\n",
       "      <th>meta.validFrom</th>\n",
       "      <th>meta.validTo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outfit.00004b4d01ca4ab0a70cf073ba74fefa</td>\n",
       "      <td>user.66d3a17f5dd149f1845bbaf223c67cc3</td>\n",
       "      <td>Yugen Black Cardigan</td>\n",
       "      <td>FWSS</td>\n",
       "      <td>The FWSS Yugen Cardigan is a form-fitted cardi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.00004b4d01ca4ab0a70cf073ba74fefa - Yuge...</td>\n",
       "      <td>1900.0000</td>\n",
       "      <td>2023-04-04 04:10:22.062</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outfit.0013691ff35b440e9dcfe1748ec184c7</td>\n",
       "      <td>user.8a140d0e20704284a656f2400b64b885</td>\n",
       "      <td>Oldina Parka Cotta</td>\n",
       "      <td>Kari Traa</td>\n",
       "      <td>The Oldina Parka from Kari Traa is a women's p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.0013691ff35b440e9dcfe1748ec184c7 - Oldi...</td>\n",
       "      <td>3500.0000</td>\n",
       "      <td>2023-02-23 12:20:27.042</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outfit.00234201fa2d4ee49a572d650c775213</td>\n",
       "      <td>user.adaf918fc0364873a48255897a2b13d8</td>\n",
       "      <td>Phantom Polaris Down Coat</td>\n",
       "      <td>Fleischer Couture</td>\n",
       "      <td>Polaris has a classic design, with a curved sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.00234201fa2d4ee49a572d650c775213 - Phan...</td>\n",
       "      <td>8000.0000</td>\n",
       "      <td>2022-05-31 16:43:55.205</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outfit.003356af26964c5084d0cc1e9f95978c</td>\n",
       "      <td>user.87234eeeecf54b99b5694a4ded75e420</td>\n",
       "      <td>Cala Long Sleeve Black</td>\n",
       "      <td>Skappel</td>\n",
       "      <td>The Cala Knitted Jumper from Skappel is a nice...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.003356af26964c5084d0cc1e9f95978c - Cala...</td>\n",
       "      <td>1800.0000</td>\n",
       "      <td>2022-10-26 06:22:05.720</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outfit.003e042f5e9e4043bf10a0284d88ce75</td>\n",
       "      <td>user.8786114165114ea0b6fbc447deae9114</td>\n",
       "      <td>2 Rose Dust Tiana Top</td>\n",
       "      <td>Maud</td>\n",
       "      <td>The Tiana Top is cut in a classic fit, and fea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.003e042f5e9e4043bf10a0284d88ce75 - 2 Ro...</td>\n",
       "      <td>1500.0000</td>\n",
       "      <td>2022-07-19 12:16:00.406</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9021</th>\n",
       "      <td>outfit.ffe4d235a016429dae41bb6399cf16d1</td>\n",
       "      <td>user.ed1650e1d15d407b925b669fb31227bd</td>\n",
       "      <td>Undercover Ash Sunglasses</td>\n",
       "      <td>Kaibosh</td>\n",
       "      <td>The Undercover Sunglasses from Kaibosh are 100...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.ffe4d235a016429dae41bb6399cf16d1 - Unde...</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>2022-08-15 17:06:41.201</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>outfit.ffe617f43d244ebc81228915cfcc6c8e</td>\n",
       "      <td>user.0e2df601218248bd9d97b882664dd978</td>\n",
       "      <td>Platinum Blazer</td>\n",
       "      <td>Riccovero</td>\n",
       "      <td>Platinum Blazer is a classic and narrow suit j...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.ffe617f43d244ebc81228915cfcc6c8e - Plat...</td>\n",
       "      <td>2800.0000</td>\n",
       "      <td>2022-11-18 13:10:41.352</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9023</th>\n",
       "      <td>outfit.ffebad2c479045a78adecdcd8f07427d</td>\n",
       "      <td>user.e6aed916b476487b85adaf0a6295578d</td>\n",
       "      <td>Bumble Dress Black Burnout Maxi</td>\n",
       "      <td>Høst &amp; Vår</td>\n",
       "      <td>The Bumble Maxi Dress from Høst &amp; Vår is a ful...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.ffebad2c479045a78adecdcd8f07427d - Bumb...</td>\n",
       "      <td>1800.0000</td>\n",
       "      <td>2023-01-05 09:12:43.847</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9024</th>\n",
       "      <td>outfit.ffeef842238f4dbdabc6c730a75aa2bd</td>\n",
       "      <td>user.5ab3daf28ecc4c5c9c5d2b6e37b97712</td>\n",
       "      <td>Black Amber Pants</td>\n",
       "      <td>Kupong Knit.wear</td>\n",
       "      <td>Feel slack and nice dressed with this pant, ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.ffeef842238f4dbdabc6c730a75aa2bd - Blac...</td>\n",
       "      <td>1200.0000</td>\n",
       "      <td>2022-02-28 11:02:29.494</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9025</th>\n",
       "      <td>outfit.fffa1b9a3db6415d806f3c48f8ab58d9</td>\n",
       "      <td>user.2faa21d6a80040ff9688ff45dca7b5b4</td>\n",
       "      <td>Yellow Shell Mellomholmene Blouse</td>\n",
       "      <td>ILAG</td>\n",
       "      <td>This beautiful blouse features an adjustable n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>outfit.fffa1b9a3db6415d806f3c48f8ab58d9 - Yell...</td>\n",
       "      <td>1300.0000</td>\n",
       "      <td>2022-10-20 10:24:35.614</td>\n",
       "      <td>9999-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9026 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id   \n",
       "0     outfit.00004b4d01ca4ab0a70cf073ba74fefa  \\\n",
       "1     outfit.0013691ff35b440e9dcfe1748ec184c7   \n",
       "2     outfit.00234201fa2d4ee49a572d650c775213   \n",
       "3     outfit.003356af26964c5084d0cc1e9f95978c   \n",
       "4     outfit.003e042f5e9e4043bf10a0284d88ce75   \n",
       "...                                       ...   \n",
       "9021  outfit.ffe4d235a016429dae41bb6399cf16d1   \n",
       "9022  outfit.ffe617f43d244ebc81228915cfcc6c8e   \n",
       "9023  outfit.ffebad2c479045a78adecdcd8f07427d   \n",
       "9024  outfit.ffeef842238f4dbdabc6c730a75aa2bd   \n",
       "9025  outfit.fffa1b9a3db6415d806f3c48f8ab58d9   \n",
       "\n",
       "                                      owner   \n",
       "0     user.66d3a17f5dd149f1845bbaf223c67cc3  \\\n",
       "1     user.8a140d0e20704284a656f2400b64b885   \n",
       "2     user.adaf918fc0364873a48255897a2b13d8   \n",
       "3     user.87234eeeecf54b99b5694a4ded75e420   \n",
       "4     user.8786114165114ea0b6fbc447deae9114   \n",
       "...                                     ...   \n",
       "9021  user.ed1650e1d15d407b925b669fb31227bd   \n",
       "9022  user.0e2df601218248bd9d97b882664dd978   \n",
       "9023  user.e6aed916b476487b85adaf0a6295578d   \n",
       "9024  user.5ab3daf28ecc4c5c9c5d2b6e37b97712   \n",
       "9025  user.2faa21d6a80040ff9688ff45dca7b5b4   \n",
       "\n",
       "                                   name              brand   \n",
       "0                  Yugen Black Cardigan               FWSS  \\\n",
       "1                   Oldina Parka Cotta           Kari Traa   \n",
       "2             Phantom Polaris Down Coat  Fleischer Couture   \n",
       "3               Cala Long Sleeve Black             Skappel   \n",
       "4                 2 Rose Dust Tiana Top               Maud   \n",
       "...                                 ...                ...   \n",
       "9021          Undercover Ash Sunglasses            Kaibosh   \n",
       "9022                    Platinum Blazer          Riccovero   \n",
       "9023    Bumble Dress Black Burnout Maxi         Høst & Vår   \n",
       "9024                  Black Amber Pants   Kupong Knit.wear   \n",
       "9025  Yellow Shell Mellomholmene Blouse               ILAG   \n",
       "\n",
       "                                            description  isPublic  isDeleted   \n",
       "0     The FWSS Yugen Cardigan is a form-fitted cardi...         1          0  \\\n",
       "1     The Oldina Parka from Kari Traa is a women's p...         1          0   \n",
       "2     Polaris has a classic design, with a curved sh...         1          0   \n",
       "3     The Cala Knitted Jumper from Skappel is a nice...         1          0   \n",
       "4     The Tiana Top is cut in a classic fit, and fea...         1          0   \n",
       "...                                                 ...       ...        ...   \n",
       "9021  The Undercover Sunglasses from Kaibosh are 100...         1          0   \n",
       "9022  Platinum Blazer is a classic and narrow suit j...         1          0   \n",
       "9023  The Bumble Maxi Dress from Høst & Vår is a ful...         1          0   \n",
       "9024  Feel slack and nice dressed with this pant, ma...         1          0   \n",
       "9025  This beautiful blouse features an adjustable n...         1          0   \n",
       "\n",
       "      type                                           keywords retailPrice   \n",
       "0     None  outfit.00004b4d01ca4ab0a70cf073ba74fefa - Yuge...   1900.0000  \\\n",
       "1     None  outfit.0013691ff35b440e9dcfe1748ec184c7 - Oldi...   3500.0000   \n",
       "2     None  outfit.00234201fa2d4ee49a572d650c775213 - Phan...   8000.0000   \n",
       "3     None  outfit.003356af26964c5084d0cc1e9f95978c - Cala...   1800.0000   \n",
       "4     None  outfit.003e042f5e9e4043bf10a0284d88ce75 - 2 Ro...   1500.0000   \n",
       "...    ...                                                ...         ...   \n",
       "9021  None  outfit.ffe4d235a016429dae41bb6399cf16d1 - Unde...   1000.0000   \n",
       "9022  None  outfit.ffe617f43d244ebc81228915cfcc6c8e - Plat...   2800.0000   \n",
       "9023  None  outfit.ffebad2c479045a78adecdcd8f07427d - Bumb...   1800.0000   \n",
       "9024  None  outfit.ffeef842238f4dbdabc6c730a75aa2bd - Blac...   1200.0000   \n",
       "9025  None  outfit.fffa1b9a3db6415d806f3c48f8ab58d9 - Yell...   1300.0000   \n",
       "\n",
       "              meta.validFrom         meta.validTo  \n",
       "0    2023-04-04 04:10:22.062  9999-01-01 00:00:00  \n",
       "1    2023-02-23 12:20:27.042  9999-01-01 00:00:00  \n",
       "2    2022-05-31 16:43:55.205  9999-01-01 00:00:00  \n",
       "3    2022-10-26 06:22:05.720  9999-01-01 00:00:00  \n",
       "4    2022-07-19 12:16:00.406  9999-01-01 00:00:00  \n",
       "...                      ...                  ...  \n",
       "9021 2022-08-15 17:06:41.201  9999-01-01 00:00:00  \n",
       "9022 2022-11-18 13:10:41.352  9999-01-01 00:00:00  \n",
       "9023 2023-01-05 09:12:43.847  9999-01-01 00:00:00  \n",
       "9024 2022-02-28 11:02:29.494  9999-01-01 00:00:00  \n",
       "9025 2022-10-20 10:24:35.614  9999-01-01 00:00:00  \n",
       "\n",
       "[9026 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mysql.connector import (connection)\n",
    "from Database_Settings import DB_SETTINGS\n",
    "import Database_connector\n",
    "\n",
    "cnx = connection.MySQLConnection(**DB_SETTINGS)\n",
    "db_connection = Database_connector.Db_Connection()\n",
    "cursor = cnx.cursor(dictionary=True)\n",
    "pictures_df = pd.read_pickle(f\"{EMBEDDINGS_SAVE_DIR}/used_picture_ids.pkl\")\n",
    "# pictures_query = \"SELECT * FROM Pictures WHERE (`Pictures`.`meta.validTo` >= '9999-01-01 00:00:00')\"\n",
    "# cursor.execute(pictures_query)\n",
    "# pcitures_results = cursor.fetchall()\n",
    "\n",
    "# pictures_df = pd.DataFrame([list(order_dict.values()) for order_dict in pcitures_results], columns=list(pcitures_results[0].keys()))\n",
    "\n",
    "cursor = cnx.cursor(dictionary=True)\n",
    "#tag_query = \"SELECT * FROM Outfits WHERE (`Outfits`.`isPublic` = TRUE AND `Outfits`.`isDeleted` = FALSE AND `Outfits`.`meta.validTo` >= '9999-01-01 00:00:00')\"\n",
    "tag_query = \"SELECT `Outfits`.`id` AS `id`, `Outfits`.`owner` AS `owner`, `Outfits`.`name` AS `name`, `Outfits`.`brand` AS `brand`, `Outfits`.`description` AS `description`, `Outfits`.`isPublic` AS `isPublic`, `Outfits`.`isDeleted` AS `isDeleted`, `Outfits`.`type` AS `type`, `Outfits`.`keywords` AS `keywords`, `Outfits`.`retailPrice` AS `retailPrice`, `Outfits`.`meta.validFrom` AS `meta.validFrom`, `Outfits`.`meta.validTo` AS `meta.validTo` FROM `Outfits` WHERE (`Outfits`.`isPublic` = TRUE AND `Outfits`.`isDeleted` = FALSE AND `Outfits`.`meta.validTo` >= '9999-01-01 00:00:00')\"\n",
    "cursor.execute(tag_query)\n",
    "outfit_results = cursor.fetchall()\n",
    "\n",
    "outfits_df_db = pd.DataFrame([list(order_dict.values()) for order_dict in outfit_results], columns=list(outfit_results[0].keys()))\n",
    "outfits_df_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [00:01, 732.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 930, picture.05ab2834ce8c40b89eb4fdbf12b3cba1 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9335it [00:12, 757.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 14162, picture.580a4eaee0614e1bab1b34a61557e4bd not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9868it [00:13, 750.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 15018, picture.5d64c136ee0445eb9d62525b785f6a70 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14408it [00:19, 744.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 22729, picture.87ffd8300c6b4ec1931d7c699de9e676 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18371it [00:24, 758.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 32058, picture.ac3c991965ea4bec86a066a154b91613 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21856it [00:29, 751.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 39150, picture.cbebaa3a8af14d32b14626ad3fd38cb1 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22384it [00:30, 743.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 40004, picture.d158acf6479f45cd8fad556522df6b1f not found in local images, skipping...\n",
      "Picture id: 40038, picture.d1907a29b851429aba22bf97f3677131 not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23890it [00:32, 743.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picture id: 42361, picture.df94ca2ef38e4f8fa2a830d883a54fbb not found in local images, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27053it [00:36, 740.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "catalog = []\n",
    "local_image_ids = os.listdir(EMBEDDINGS_PICTURES_DIR)\n",
    "found_locally = []\n",
    "for index, picture_row in tqdm(pictures_df.iterrows()):\n",
    "\n",
    "    #picture_row = pictures_df[pictures_df[\"id\"] == filtered_picture_id]\n",
    "    filtered_picture_id = picture_row[\"id\"]\n",
    "    picture_outfit_id = picture_row[\"owner\"]\n",
    "\n",
    "    picture_index = picture_row.index[0]\n",
    "    outfit_row = outfits_df_db[outfits_df_db[\"id\"] == picture_outfit_id]\n",
    "    \n",
    "    found = filtered_picture_id in local_image_ids \n",
    "    found_outfit = len(outfit_row) != 0\n",
    "    found_locally.append(found and found_outfit)\n",
    "    if not found:\n",
    "        print(f\"Picture id: {index}, {filtered_picture_id} not found in local images, skipping...\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    if not found_outfit:\n",
    "        continue\n",
    "\n",
    "    picture_caption = f\"{outfit_row['name'].values[0]} - {outfit_row['description'].values[0]}\"\n",
    "    #print(f\"{picture_index}: Picture id: {filtered_picture_id}, outfit id: {picture_outfit_id}\")\n",
    "    catalog.append({\"id\": picture_index, \"image\":filtered_picture_id, \"caption\": picture_caption})\n",
    "\n",
    "pictures_df[\"found_locally\"] = found_locally\n",
    "pictures_df = pictures_df[pictures_df[\"found_locally\"]].drop(columns=[\"found_locally\"])\n",
    "\n",
    "import pickle\n",
    "with open(f\"{EMBEDDINGS_SAVE_DIR}/catalog.pkl\", \"wb\") as f:\n",
    "    pickle.dump(catalog, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"{EMBEDDINGS_SAVE_DIR}/catalog.pkl\", \"rb\") as f:\n",
    "    catalog = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache is at /home/kaborg15/.cache/fashion_clip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/kaborg15/fashion-clip\")\n",
    "from fashion_clip.fashion_clip import FashionCLIP, FCLIPDataset\n",
    "from fashion_clip.utils import get_cache_directory, display_images\n",
    "print(\"Cache is at {}\".format(get_cache_directory()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d8b31fd16d4edb8c7333a9e6048c5f3623ef9d7_13d3b48a2e31d7bf49dda47c427c8777e7af575e8bf1b9d4d0ebc15c5b0e23f7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 571/838 [26:23<12:39,  2.84s/it]"
     ]
    }
   ],
   "source": [
    "dataset = FCLIPDataset('farfetch_local',\n",
    "                       image_source_path=EMBEDDINGS_PICTURES_DIR,\n",
    "                       image_source_type='local',\n",
    "                       catalog=catalog)\n",
    "fclip = FashionCLIP(\"fashion-clip\", dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fclip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kaborg15\\PycharmProjects\\FREja\\Data_Science_Notebooks\\Similarity_Evaluator_Model_Producer_CLIP.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaborg15/PycharmProjects/FREja/Data_Science_Notebooks/Similarity_Evaluator_Model_Producer_CLIP.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     os\u001b[39m.\u001b[39mmkdir(MODEL_SAVE_DIR)\n\u001b[1;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaborg15/PycharmProjects/FREja/Data_Science_Notebooks/Similarity_Evaluator_Model_Producer_CLIP.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pictures_df\u001b[39m.\u001b[39mto_pickle(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mMODEL_SAVE_DIR\u001b[39m}\u001b[39;00m\u001b[39m/pictures_df.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kaborg15/PycharmProjects/FREja/Data_Science_Notebooks/Similarity_Evaluator_Model_Producer_CLIP.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mMODEL_SAVE_DIR\u001b[39m}\u001b[39;00m\u001b[39m/image_vectors.npy\u001b[39m\u001b[39m\"\u001b[39m, fclip\u001b[39m.\u001b[39mimage_vectors)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fclip' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "MODEL_SAVE_DIR = f\"{EMBEDDINGS_SAVE_DIR}/clip_model/\"\n",
    "\n",
    "if not os.path.isdir(MODEL_SAVE_DIR):\n",
    "    os.mkdir(MODEL_SAVE_DIR)\n",
    "\n",
    "\n",
    "pictures_df.to_pickle(f\"{MODEL_SAVE_DIR}/pictures_df.pkl\")\n",
    "np.save(f\"{MODEL_SAVE_DIR}/image_vectors.npy\", fclip.image_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/google/auth/_default.py:78: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PKL name: ViT_H_14_E2E_final.pkl | Model: VisionTransformer | Weights: ViT_H_14_Weights | IMAGENET1K_SWAG_E2E_V1\n",
      "Generating embeddings from ViT_H_14_E2E_final to ViT_H_14_E2E_final.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [2:27:46<00:00, 44.33s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to ViT_H_tensors.pt and ViT_H_ids.pkl\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import Image_Embedding_File_Handler\n",
    "import random\n",
    "\n",
    "INFERENCE_TIME_LOG_FILE = \"Pickled_Data/inference_time_log.txt\"\n",
    "\n",
    "def log_inference_time(config_class, embedding_shape, inference_time_array):\n",
    "    with open(INFERENCE_TIME_LOG_FILE, \"a\") as f:\n",
    "        f.write(f\"\\nModel: {config_class.model_save_name}, shape: {embedding_shape}\\nmean: {inference_time_array.mean()}, values: {inference_time_array}\")\n",
    "\n",
    "\n",
    "\n",
    "def get_df_embeddings(base_df, config_class : Embedding_Config):\n",
    "    # display_out = ipywidgets.HTML()\n",
    "    # display(display_out)\n",
    "\n",
    "    inference_time_log = []\n",
    "    model_config = config_class()\n",
    "    print(f\"Generating embeddings from {type(model_config).__name__} to {model_config.model_save_name}...\")\n",
    "    split_dfs = np.array_split(base_df, DF_SPLITS)\n",
    "    for df_split in tqdm(split_dfs[:]):\n",
    "        df_images = model_config.load_images(df_split[\"id\"])\n",
    "\n",
    "        start_time = time.time()\n",
    "        df_embeddings = model_config.get_embeddings(df_images)\n",
    "        embedding_shape = df_embeddings.shape\n",
    "        df_embeddings = list(df_embeddings)\n",
    "        inference_time_log.append(time.time() - start_time)\n",
    "\n",
    "        df_split[\"embeddings\"] = df_embeddings\n",
    "    embedding_df = pd.concat(split_dfs)\n",
    "    embeddings_save_folder = os.path.join(EMBEDDINGS_SAVE_DIR, model_config.model_save_name)\n",
    "    try:\n",
    "        Image_Embedding_File_Handler.save_embeddings(embedding_df, save_dir=embeddings_save_folder)\n",
    "    except:\n",
    "        embedding_df = embedding_df.dropna()\n",
    "        embeddings_save_folder += str(random.randint(0, 1000))\n",
    "        #return embedding_df\n",
    "        Image_Embedding_File_Handler.save_embeddings(embedding_df, save_dir=embeddings_save_folder)\n",
    "        \n",
    "    #embedding_df.to_pickle(os.path.join(EMBEDDINGS_SAVE_DIR, model_config.model_save_name))\n",
    "    log_inference_time(model_config, embedding_shape, np.array(inference_time_log))\n",
    "    return embedding_df\n",
    "\n",
    "class_configs = [EfficientNet_V2_L_final, ConvNext_Large_v1_final]\n",
    "for config_class in class_configs:\n",
    "    get_df_embeddings(pictures_df, config_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3781f7017ca0b9de91b3fa2496fb023ed6cbd54c6077891b434d73e407680117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
